# T5-small Full Fine-Tuning Test Configuration
# Quick 15-minute test run for validation
# Author: Nathan Chung
# Course: COMP3710 Pattern Analysis

# Dataset Configuration
dataset:
  name: "BioLaySumm/BioLaySumm2025-LaymanRRG-opensource-track"
  max_source_length: 256      # Shorter for faster test
  max_target_length: 128      # Shorter for faster test
  seed: 42                    # Random seed for reproducible shuffling
  local_data_path: null       # Optional local data path override

# Model Configuration
model:
  name: "t5-small"            # T5-small for full fine-tuning
  torch_dtype: "bfloat16"     # Mixed precision for memory efficiency

# Training Configuration
training:
  strategy: "full"            # Full fine-tuning strategy
  batch_size: 2               # Very small batch for test
  gradient_accumulation_steps: 2  # Effective batch size = 2 * 2 = 4
  learning_rate: 5e-5         # Lower learning rate for full fine-tuning
  num_epochs: 1               # Just 1 epoch for test
  max_steps: 25               # Very few steps for quick test
  warmup_steps: 5             # Small warmup
  weight_decay: 0.01          # L2 regularization
  max_grad_norm: 1.0          # Gradient clipping
  
  # Logging and evaluation (frequent for test)
  logging_steps: 5
  eval_steps: 20
  save_steps: 20  # Must be multiple of eval_steps
  load_best_model_at_end: false  # Don't load best for test
  
  # Early stopping
  early_stopping_patience: 3
  early_stopping_threshold: 0.001

# Full Fine-Tuning Configuration
full_finetuning:
  enabled: true
  gradient_checkpointing: true  # Enable for memory efficiency

# Hardware Configuration
hardware:
  device: "cuda"              # Use CUDA if available
  dataloader_num_workers: 2   # Fewer workers for test
  pin_memory: true            # Pin memory for faster data transfer

# Output Configuration
output:
  root: "reports/test_run_full"  # Test output directory
  run_name: "t5-small-full-test"
  report_to: []               # No reporting for test

# Reproducibility
reproducibility:
  seed: 42                    # Random seed
  data_seed: 42               # Data shuffling seed
  deterministic: true         # Deterministic training

# Evaluation Configuration
evaluation:
  max_new_tokens: 128         # Shorter generation for test
  num_beams: 2                # Fewer beams for speed
  length_penalty: 0.6         # Length penalty
  no_repeat_ngram_size: 3     # No repeat n-gram size
  early_stopping: true        # Early stopping in generation

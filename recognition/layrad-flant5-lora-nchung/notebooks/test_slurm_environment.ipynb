{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Slurm Environment Test Notebook\n",
        "\n",
        "This notebook emulates the exact Slurm environment to test both LoRA and Full Fine-tuning before submitting to Rangpur.\n",
        "\n",
        "## What This Tests:\n",
        "- ‚úÖ `torchrun` with `--standalone --nproc_per_node=1`\n",
        "- ‚úÖ CUDA multiprocessing with `spawn` method\n",
        "- ‚úÖ Model loading order (datasets first, then model)\n",
        "- ‚úÖ Both LoRA and Full FT training strategies\n",
        "- ‚úÖ Automatic evaluation after training\n",
        "- ‚úÖ All the fixes we applied\n",
        "\n",
        "## Usage:\n",
        "1. Run the setup cell\n",
        "2. Choose which test to run (LoRA or Full FT)\n",
        "3. Monitor for any errors\n",
        "4. If successful, submit to Rangpur with confidence!\n",
        "\n",
        "## Important Note:\n",
        "This notebook handles both repository structures:\n",
        "- **Slurm**: Files directly in root (`/home/Student/s4800977/comp3710/a3/src/`, etc.)\n",
        "- **GitHub**: Files in subdirectory (`recognition/layrad-flant5-lora-nchung/src/`, etc.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup (Mirrors Slurm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import multiprocessing\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Set up environment variables (mirrors Slurm)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use first GPU\n",
        "os.environ['HF_HOME'] = '/content/hf_cache'  # HuggingFace cache\n",
        "os.environ['TRANSFORMERS_CACHE'] = '/content/hf_cache'\n",
        "\n",
        "# Create cache directory\n",
        "Path('/content/hf_cache').mkdir(exist_ok=True)\n",
        "\n",
        "print(\"üîß Environment Setup Complete\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "print(f\"Python: {sys.executable}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Multiprocessing start method: {multiprocessing.get_start_method()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Repository & Navigate to Correct Directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository and navigate to correct directory\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Set project root (mirrors Slurm)\n",
        "PROJECT_ROOT = \"/content/comp3710/a3\"\n",
        "REPO_URL = \"https://github.com/nchung/comp3710-a3.git\"  # Replace with your actual repo\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    subprocess.run([\"rm\", \"-rf\", PROJECT_ROOT], check=True)\n",
        "\n",
        "# Clone repository\n",
        "print(f\"üì• Cloning repository to {PROJECT_ROOT}...\")\n",
        "subprocess.run([\"git\", \"clone\", REPO_URL, PROJECT_ROOT], check=True)\n",
        "\n",
        "# Change to project directory\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print(f\"‚úÖ Repository cloned and changed to: {os.getcwd()}\")\n",
        "\n",
        "# List contents to verify\n",
        "print(\"\\nüìÅ Repository contents:\")\n",
        "subprocess.run([\"ls\", \"-la\"], check=True)\n",
        "\n",
        "# Check for key files in root directory (Slurm structure)\n",
        "print(\"\\nüîç Checking for key files in root:\")\n",
        "key_files = [\"requirements.txt\", \"src/train.py\", \"configs/\", \"scripts/\"]\n",
        "root_files_found = 0\n",
        "for file in key_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"‚úÖ Found: {file}\")\n",
        "        root_files_found += 1\n",
        "    else:\n",
        "        print(f\"‚ùå Missing: {file}\")\n",
        "\n",
        "# If files not found in root, look for subdirectory structure\n",
        "if root_files_found < 2:  # If we don't have most files in root\n",
        "    print(\"\\nüîç Files not in root, checking subdirectories...\")\n",
        "    subprocess.run([\"find\", \".\", \"-name\", \"train.py\", \"-type\", \"f\"], check=True)\n",
        "    subprocess.run([\"find\", \".\", \"-name\", \"requirements.txt\", \"-type\", \"f\"], check=True)\n",
        "    \n",
        "    # Look for the actual project directory\n",
        "    for root, dirs, files in os.walk(\".\"):\n",
        "        if \"train.py\" in files and \"requirements.txt\" in files:\n",
        "            actual_project_dir = root\n",
        "            print(f\"\\n‚úÖ Found actual project directory: {actual_project_dir}\")\n",
        "            print(f\"üìÅ Contents of {actual_project_dir}:\")\n",
        "            subprocess.run([\"ls\", \"-la\", actual_project_dir], check=True)\n",
        "            \n",
        "            # Change to the actual project directory\n",
        "            os.chdir(actual_project_dir)\n",
        "            print(f\"‚úÖ Changed to actual project directory: {os.getcwd()}\")\n",
        "            break\n",
        "\n",
        "# Show final directory structure\n",
        "print(\"\\nüìÇ Final directory structure:\")\n",
        "subprocess.run([\"find\", \".\", \"-type\", \"d\", \"-maxdepth\", \"2\"], check=True)\n",
        "\n",
        "# Verify we're in the right place\n",
        "print(f\"\\nüéØ Current working directory: {os.getcwd()}\")\n",
        "print(\"üîç Final check for key files:\")\n",
        "for file in key_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"‚úÖ Found: {file}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Missing: {file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies (Robust Version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (robust version that handles missing requirements.txt)\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Check if requirements.txt exists and what's in it\n",
        "if os.path.exists(\"requirements.txt\"):\n",
        "    print(\"üìÑ Found requirements.txt:\")\n",
        "    with open(\"requirements.txt\", \"r\") as f:\n",
        "        content = f.read()\n",
        "        print(content)\n",
        "    \n",
        "    try:\n",
        "        # Try to install from requirements.txt\n",
        "        subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
        "        print(\"‚úÖ Requirements.txt installed successfully\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ö†Ô∏è Requirements.txt failed: {e}\")\n",
        "        print(\"üì¶ Installing core packages manually...\")\n",
        "        \n",
        "        # Install core packages manually\n",
        "        core_packages = [\n",
        "            \"transformers>=4.30.0\",\n",
        "            \"datasets>=2.12.0\", \n",
        "            \"peft>=0.4.0\",\n",
        "            \"evaluate>=0.4.0\",\n",
        "            \"rouge-score>=0.1.2\",\n",
        "            \"accelerate>=0.20.0\",\n",
        "            \"torch>=2.0.0\",\n",
        "            \"torchvision\",\n",
        "            \"torchaudio\"\n",
        "        ]\n",
        "        \n",
        "        for package in core_packages:\n",
        "            try:\n",
        "                subprocess.run([\"pip\", \"install\", package], check=True)\n",
        "                print(f\"‚úÖ Installed {package}\")\n",
        "            except subprocess.CalledProcessError:\n",
        "                print(f\"‚ö†Ô∏è Failed to install {package}\")\n",
        "else:\n",
        "    print(\"‚ùå requirements.txt not found, installing core packages...\")\n",
        "    \n",
        "    # Install core packages\n",
        "    core_packages = [\n",
        "        \"transformers>=4.30.0\",\n",
        "        \"datasets>=2.12.0\", \n",
        "        \"peft>=0.4.0\",\n",
        "        \"evaluate>=0.4.0\",\n",
        "        \"rouge-score>=0.1.2\",\n",
        "        \"accelerate>=0.20.0\"\n",
        "    ]\n",
        "    \n",
        "    for package in core_packages:\n",
        "        try:\n",
        "            subprocess.run([\"pip\", \"install\", package], check=True)\n",
        "            print(f\"‚úÖ Installed {package}\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"‚ö†Ô∏è Failed to install {package}\")\n",
        "\n",
        "print(\"‚úÖ Dependencies installation complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Configuration Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test that config files exist and are valid\n",
        "import yaml\n",
        "\n",
        "configs_to_test = [\n",
        "    \"configs/train_flant5_base_lora.yaml\",\n",
        "    \"configs/train_t5_small_full.yaml\"\n",
        "]\n",
        "\n",
        "for config_path in configs_to_test:\n",
        "    print(f\"\\nüîç Testing {config_path}...\")\n",
        "    \n",
        "    if not os.path.exists(config_path):\n",
        "        print(f\"‚ùå Config file not found: {config_path}\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = yaml.safe_load(f)\n",
        "        \n",
        "        print(f\"‚úÖ Config loaded successfully\")\n",
        "        print(f\"   Model: {config.get('model', {}).get('name', 'Not specified')}\")\n",
        "        print(f\"   Strategy: {config.get('training', {}).get('strategy', 'Not specified')}\")\n",
        "        print(f\"   Output dir: {config.get('output_dir', 'Not specified')}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading config: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Configuration testing complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test LoRA Training (Mirrors Slurm Script)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test LoRA training with torchrun (exact Slurm command)\n",
        "print(\"üöÄ Testing LoRA Training with torchrun...\")\n",
        "print(\"This mirrors: conda run -n torch torchrun --standalone --nproc_per_node=1 src/train.py configs/train_flant5_base_lora.yaml\")\n",
        "\n",
        "# Set multiprocessing start method to spawn (our fix)\n",
        "multiprocessing.set_start_method('spawn', force=True)\n",
        "print(f\"‚úÖ Multiprocessing start method set to: {multiprocessing.get_start_method()}\")\n",
        "\n",
        "# Run the exact command from Slurm script\n",
        "cmd = [\n",
        "    \"python\", \"-m\", \"torch.distributed.run\",  # This is torchrun\n",
        "    \"--standalone\",\n",
        "    \"--nproc_per_node=1\",\n",
        "    \"src/train.py\",\n",
        "    \"configs/train_flant5_base_lora.yaml\"\n",
        "]\n",
        "\n",
        "print(f\"\\nüîß Running command: {' '.join(cmd)}\")\n",
        "print(\"\\nüìä Training output:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Run the training command\n",
        "    result = subprocess.run(cmd, capture_output=False, text=True, cwd=os.getcwd())\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"‚úÖ LoRA Training completed successfully!\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"‚ùå LoRA Training failed with exit code: {result.returncode}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error running LoRA training: {e}\")\n",
        "\n",
        "print(\"\\nüîç Checking for output files...\")\n",
        "if os.path.exists(\"checkpoints/flan-t5-base-lora-biolaysumm\"):\n",
        "    print(\"‚úÖ LoRA checkpoint directory created\")\n",
        "    subprocess.run([\"ls\", \"-la\", \"checkpoints/flan-t5-base-lora-biolaysumm\"], check=True)\n",
        "else:\n",
        "    print(\"‚ùå LoRA checkpoint directory not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Slurm Environment Test Notebook\n",
        "\n",
        "This notebook emulates the exact Slurm environment to test both LoRA and Full Fine-tuning before submitting to Rangpur.\n",
        "\n",
        "## What This Tests:\n",
        "- ‚úÖ `torchrun` with `--standalone --nproc_per_node=1`\n",
        "- ‚úÖ CUDA multiprocessing with `spawn` method\n",
        "- ‚úÖ Model loading order (datasets first, then model)\n",
        "- ‚úÖ Both LoRA and Full FT training strategies\n",
        "- ‚úÖ Automatic evaluation after training\n",
        "- ‚úÖ All the fixes we applied\n",
        "\n",
        "## Usage:\n",
        "1. Run the setup cell\n",
        "2. Choose which test to run (LoRA or Full FT)\n",
        "3. Monitor for any errors\n",
        "4. If successful, submit to Rangpur with confidence!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup (Mirrors Slurm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import multiprocessing\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Set up environment variables (mirrors Slurm)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use first GPU\n",
        "os.environ['HF_HOME'] = '/content/hf_cache'  # HuggingFace cache\n",
        "os.environ['TRANSFORMERS_CACHE'] = '/content/hf_cache'\n",
        "\n",
        "# Create cache directory\n",
        "Path('/content/hf_cache').mkdir(exist_ok=True)\n",
        "\n",
        "print(\"üîß Environment Setup Complete\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "print(f\"Python: {sys.executable}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Multiprocessing start method: {multiprocessing.get_start_method()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Repository (Mirrors Slurm Script)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository (mirrors Slurm script behavior)\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Set project root (mirrors Slurm)\n",
        "PROJECT_ROOT = \"/content/comp3710/a3\"\n",
        "REPO_URL = \"https://github.com/nchung/comp3710-a3.git\"  # Replace with your actual repo\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    subprocess.run([\"rm\", \"-rf\", PROJECT_ROOT], check=True)\n",
        "\n",
        "# Clone repository\n",
        "print(f\"üì• Cloning repository to {PROJECT_ROOT}...\")\n",
        "subprocess.run([\"git\", \"clone\", REPO_URL, PROJECT_ROOT], check=True)\n",
        "\n",
        "# Change to project directory\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print(f\"‚úÖ Repository cloned and changed to: {os.getcwd()}\")\n",
        "\n",
        "# List contents to verify\n",
        "print(\"\\nüìÅ Repository contents:\")\n",
        "subprocess.run([\"ls\", \"-la\"], check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies (Mirrors Slurm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (mirrors Slurm script)\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Install from requirements.txt\n",
        "subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n",
        "\n",
        "# Install additional packages that might be needed\n",
        "subprocess.run([\"pip\", \"install\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"], check=True)\n",
        "\n",
        "print(\"‚úÖ Dependencies installed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test Configuration Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test that config files exist and are valid\n",
        "import yaml\n",
        "\n",
        "configs_to_test = [\n",
        "    \"configs/train_flant5_base_lora.yaml\",\n",
        "    \"configs/train_t5_small_full.yaml\"\n",
        "]\n",
        "\n",
        "for config_path in configs_to_test:\n",
        "    print(f\"\\nüîç Testing {config_path}...\")\n",
        "    \n",
        "    if not os.path.exists(config_path):\n",
        "        print(f\"‚ùå Config file not found: {config_path}\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = yaml.safe_load(f)\n",
        "        \n",
        "        print(f\"‚úÖ Config loaded successfully\")\n",
        "        print(f\"   Model: {config.get('model', {}).get('name', 'Not specified')}\")\n",
        "        print(f\"   Strategy: {config.get('training', {}).get('strategy', 'Not specified')}\")\n",
        "        print(f\"   Output dir: {config.get('output_dir', 'Not specified')}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading config: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Configuration testing complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test LoRA Training (Mirrors Slurm Script)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test LoRA training with torchrun (exact Slurm command)\n",
        "print(\"üöÄ Testing LoRA Training with torchrun...\")\n",
        "print(\"This mirrors: conda run -n torch torchrun --standalone --nproc_per_node=1 src/train.py configs/train_flant5_base_lora.yaml\")\n",
        "\n",
        "# Set multiprocessing start method to spawn (our fix)\n",
        "multiprocessing.set_start_method('spawn', force=True)\n",
        "print(f\"‚úÖ Multiprocessing start method set to: {multiprocessing.get_start_method()}\")\n",
        "\n",
        "# Run the exact command from Slurm script\n",
        "cmd = [\n",
        "    \"python\", \"-m\", \"torch.distributed.run\",  # This is torchrun\n",
        "    \"--standalone\",\n",
        "    \"--nproc_per_node=1\",\n",
        "    \"src/train.py\",\n",
        "    \"configs/train_flant5_base_lora.yaml\"\n",
        "]\n",
        "\n",
        "print(f\"\\nüîß Running command: {' '.join(cmd)}\")\n",
        "print(\"\\nüìä Training output:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Run the training command\n",
        "    result = subprocess.run(cmd, capture_output=False, text=True, cwd=PROJECT_ROOT)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"‚úÖ LoRA Training completed successfully!\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"‚ùå LoRA Training failed with exit code: {result.returncode}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error running LoRA training: {e}\")\n",
        "\n",
        "print(\"\\nüîç Checking for output files...\")\n",
        "if os.path.exists(\"checkpoints/flan-t5-base-lora-biolaysumm\"):\n",
        "    print(\"‚úÖ LoRA checkpoint directory created\")\n",
        "    subprocess.run([\"ls\", \"-la\", \"checkpoints/flan-t5-base-lora-biolaysumm\"], check=True)\n",
        "else:\n",
        "    print(\"‚ùå LoRA checkpoint directory not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Full Fine-tuning Training (Mirrors Slurm Script)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Full Fine-tuning with torchrun (exact Slurm command)\n",
        "print(\"üöÄ Testing Full Fine-tuning Training with torchrun...\")\n",
        "print(\"This mirrors: conda run -n torch torchrun --standalone --nproc_per_node=1 src/train.py configs/train_t5_small_full.yaml\")\n",
        "\n",
        "# Set multiprocessing start method to spawn (our fix)\n",
        "multiprocessing.set_start_method('spawn', force=True)\n",
        "print(f\"‚úÖ Multiprocessing start method set to: {multiprocessing.get_start_method()}\")\n",
        "\n",
        "# Run the exact command from Slurm script\n",
        "cmd = [\n",
        "    \"python\", \"-m\", \"torch.distributed.run\",  # This is torchrun\n",
        "    \"--standalone\",\n",
        "    \"--nproc_per_node=1\",\n",
        "    \"src/train.py\",\n",
        "    \"configs/train_t5_small_full.yaml\"\n",
        "]\n",
        "\n",
        "print(f\"\\nüîß Running command: {' '.join(cmd)}\")\n",
        "print(\"\\nüìä Training output:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Run the training command\n",
        "    result = subprocess.run(cmd, capture_output=False, text=True, cwd=PROJECT_ROOT)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"‚úÖ Full Fine-tuning Training completed successfully!\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"‚ùå Full Fine-tuning Training failed with exit code: {result.returncode}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error running Full Fine-tuning training: {e}\")\n",
        "\n",
        "print(\"\\nüîç Checking for output files...\")\n",
        "if os.path.exists(\"checkpoints/t5-small-full-biolaysumm\"):\n",
        "    print(\"‚úÖ Full FT checkpoint directory created\")\n",
        "    subprocess.run([\"ls\", \"-la\", \"checkpoints/t5-small-full-biolaysumm\"], check=True)\n",
        "else:\n",
        "    print(\"‚ùå Full FT checkpoint directory not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Evaluation Script (Mirrors Slurm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test evaluation script (mirrors Slurm eval_runner calls)\n",
        "print(\"üîç Testing Evaluation Script...\")\n",
        "\n",
        "# Test LoRA evaluation\n",
        "if os.path.exists(\"checkpoints/flan-t5-base-lora-biolaysumm\"):\n",
        "    print(\"\\nüìä Testing LoRA Evaluation...\")\n",
        "    cmd = [\"python\", \"src/eval_runner.py\", \"configs/train_flant5_base_lora.yaml\"]\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(cmd, capture_output=False, text=True, cwd=PROJECT_ROOT)\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ LoRA Evaluation completed successfully!\")\n",
        "        else:\n",
        "            print(f\"‚ùå LoRA Evaluation failed with exit code: {result.returncode}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error running LoRA evaluation: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping LoRA evaluation - no checkpoint found\")\n",
        "\n",
        "# Test Full FT evaluation\n",
        "if os.path.exists(\"checkpoints/t5-small-full-biolaysumm\"):\n",
        "    print(\"\\nüìä Testing Full FT Evaluation...\")\n",
        "    cmd = [\"python\", \"src/eval_runner.py\", \"configs/train_t5_small_full.yaml\"]\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(cmd, capture_output=False, text=True, cwd=PROJECT_ROOT)\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Full FT Evaluation completed successfully!\")\n",
        "        else:\n",
        "            print(f\"‚ùå Full FT Evaluation failed with exit code: {result.returncode}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error running Full FT evaluation: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping Full FT evaluation - no checkpoint found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of test results\n",
        "print(\"üìã SLURM ENVIRONMENT TEST SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check what was created\n",
        "checkpoints_dir = Path(\"checkpoints\")\n",
        "if checkpoints_dir.exists():\n",
        "    print(\"\\nüìÅ Checkpoint directories created:\")\n",
        "    for item in checkpoints_dir.iterdir():\n",
        "        if item.is_dir():\n",
        "            print(f\"   ‚úÖ {item.name}\")\n",
        "            \n",
        "            # Check for reports\n",
        "            reports_dir = item / \"reports\"\n",
        "            if reports_dir.exists():\n",
        "                print(f\"      üìä Reports: {list(reports_dir.glob('*'))}\")\n",
        "            else:\n",
        "                print(f\"      ‚ö†Ô∏è No reports directory\")\n",
        "else:\n",
        "    print(\"‚ùå No checkpoints directory found\")\n",
        "\n",
        "print(\"\\nüéØ Next Steps:\")\n",
        "print(\"1. If all tests passed, your Slurm scripts should work on Rangpur\")\n",
        "print(\"2. Submit both training jobs to Rangpur\")\n",
        "print(\"3. Monitor the logs for any issues\")\n",
        "print(\"4. Check the results in the checkpoint directories\")\n",
        "\n",
        "print(\"\\n‚úÖ Slurm environment test complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

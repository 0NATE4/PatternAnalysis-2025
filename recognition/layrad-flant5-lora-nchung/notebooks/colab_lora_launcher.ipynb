{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Launcher – LoRA Training for FLAN-T5 on BioLaySumm\n",
        "\n",
        "This notebook mirrors the Slurm script `scripts/slurm/train_flant5_base_lora.sbatch` and runs the repository code directly (no notebook-specific code).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 1) GPU and environment\n",
        "!nvidia-smi || true\n",
        "!pip install -q \"transformers>=4.40\" \"datasets>=2.18\" \"evaluate>=0.4.2\" peft rouge-score accelerate tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 2) Clone repo and cd\n",
        "!rm -rf PatternAnalysis-2025 || true\n",
        "!git clone https://github.com/0NATE4/PatternAnalysis-2025.git\n",
        "%cd PatternAnalysis-2025/recognition/layrad-flant5-lora-nchung\n",
        "!pwd\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 3) Mount Google Drive for persistent checkpoints\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Drive mounted')\n",
        "\n",
        "# Create backup directory in Drive\n",
        "!mkdir -p /content/drive/MyDrive/Colab\\ Notebooks/layrad-checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 4) Check for existing checkpoints\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Check local output directory\n",
        "output_dir = \"./outputs/lora_training\"\n",
        "local_checkpoints = glob.glob(f\"{output_dir}/checkpoint-*\")\n",
        "\n",
        "# Check Drive backup\n",
        "drive_checkpoints = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/layrad-checkpoints/lora-checkpoint-*\")\n",
        "\n",
        "print(f\"Local checkpoints: {len(local_checkpoints)}\")\n",
        "print(f\"Drive checkpoints: {len(drive_checkpoints)}\")\n",
        "\n",
        "if local_checkpoints:\n",
        "    latest_local = max(local_checkpoints, key=os.path.getctime)\n",
        "    print(f\"Latest local: {latest_local}\")\n",
        "    \n",
        "if drive_checkpoints:\n",
        "    latest_drive = max(drive_checkpoints, key=os.path.getctime)\n",
        "    print(f\"Latest drive: {latest_drive}\")\n",
        "    \n",
        "    # Copy latest from Drive if no local checkpoint\n",
        "    if not local_checkpoints:\n",
        "        print(\"Copying latest checkpoint from Drive...\")\n",
        "        !cp -r \"{latest_drive}\" \"{output_dir}/\"\n",
        "        print(\"Checkpoint restored from Drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 5) Run LoRA training (will auto-resume from checkpoint)\n",
        "!python src/train.py configs/train_flant5_base_lora.yaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 6) Backup final checkpoint to Drive\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "# Find latest checkpoint\n",
        "checkpoints = glob.glob(f\"{output_dir}/checkpoint-*\")\n",
        "if checkpoints:\n",
        "    latest = max(checkpoints, key=os.path.getctime)\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    backup_name = f\"lora-checkpoint-{timestamp}\"\n",
        "    \n",
        "    print(f\"Backing up {latest} to Drive as {backup_name}\")\n",
        "    shutil.copytree(latest, f\"/content/drive/MyDrive/Colab Notebooks/layrad-checkpoints/{backup_name}\")\n",
        "    print(\"Backup complete!\")\n",
        "else:\n",
        "    print(\"No checkpoints found to backup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Launcher – LoRA Training for FLAN-T5 on BioLaySumm\n",
        "\n",
        "This notebook mirrors the Slurm script `scripts/slurm/train_flant5_base_lora.sbatch` and runs the repository code directly (no notebook-specific code).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 1) GPU and environment\n",
        "!nvidia-smi || true\n",
        "!pip install -q \"transformers>=4.40\" \"datasets>=2.18\" \"evaluate>=0.4.2\" peft rouge-score accelerate tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 2) Clone repo and cd\n",
        "!rm -rf PatternAnalysis-2025 || true\n",
        "!git clone https://github.com/0NATE4/PatternAnalysis-2025.git\n",
        "%cd PatternAnalysis-2025/recognition/layrad-flant5-lora-nchung\n",
        "!pwd\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 3) Optional: mount Google Drive for persistent checkpoints\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print('Drive mounted')\n",
        "    # optionally override output dir in YAML via sed below\n",
        "except Exception as e:\n",
        "    print('Drive not available:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title 4) Run LoRA training\n",
        "!python src/train.py configs/train_flant5_base_lora.yaml\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
